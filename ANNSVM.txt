=» We Used ANN Classifier For Train A Type of Deep learning Models upon our Dataset " spam-or-ham classification problem " .
       =»Firstly , Importing necessary modules from keras libirary :
**
              from keras.models import Sequential
              from keras.layers import Dense 
**
       =»Then , we create An object of the sequential Model " responsible for building a model consists of sequence of layers " 
**          
              classifier = Sequential()
**
         =» we Built our sequential model from 3 Layers :
              =»First Hidden Layer with " Input_dim = 8035 , and output_dim = 3900 " and we initialize the network weights of " uniform " distribution , in this case , weights are random numbers between 0 and 0.05 because that is the default uniform weight initialization in Keras , The Activation function of rectifier ('relu').
             =»Second Hidden Layer with " output_dim = 1950 , The Activation function ('relu') .
             =» Third Layer is The prediction output layer with output_dim of 1 neuron for predicting the class of text ( spam or ham ), Activation function is ('segmoid') to ensure our network output is between 0 and 1 and easy to map to either a probability of classes.
**
            classifier.add(Dense(output_dim = 3900, init = 'uniform', activation = 'relu', input_dim = 8035)) 
           classifier.add(Dense(output_dim = 1950, init = 'uniform', activation = 'relu')) 
            classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))
**
      =» Then , We comiled our Network with logarithmic loss function (' binary_crossentropy') which for binary classification problem Defined in Keras , the efficient gradient descent Optimizer “adam” also predefined in keras which used to search through different weights , and The Accuracy Metric .

**
       classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

**
        =» Then , Fit the network by our splitted Dataset by " fit " function with our training observations " features_train " and its labels " labels_train" , defining the number of "epochs" (Iterations for spesific number of instances with different weights values ) and the : "batch_size" ( the number of instancez that are evaluated before a weight update in the network ) .
**
       classifier.fit(X, Y, epochs=195, batch_size=20)
**
         =» Then , Evaluating model on our training set , This will generate a prediction for each input and output pair and collect scores, including the average loss and any metrics you have configured, such as accuracy.
**
        score = classifier.evaluate(featurs_train , labels_train , verbose=0 )
**
        =» Then , predicting some labels of miss_labeled test data we had splited before .
**
          Y_pred = classifier.predict (features_test)
          y_pred = (y_pred > 0.5)
**
        =» Finally , Making the confusion Matrix (TP, TN , FP , FN).
**
          from sklearn.metrics import confusion_matrix
         cm = confusion_matrix(labels_test, y_pred)
** 
**** END Of Ann Model *****
=» Using Another Machine Learning Algorithm for Binary classification problem , we have used " support vector machine " non-linear classifier to separately deviding our to classes " Spam , Ham " by A decision boundary .
      =» Using " Sklearn " library we import The class of SVM called ('svc').
**
        from sklearn.svm import SVC 
**
      =»Then define our model with svc object The non-linear kernel of ('segmoid') which makes a non-linear decision boundary  between the two classes (sapm , ham) with probabilstic predction And fit our model with our training data (obsrrvations and its labels ).
**
        svc = SVC(kernel='sigmoid').
        svc.fit(features_train, labels_train).
**
      =» Then Predict the labels of test observations we have splitted before.
**
      prediction = svc.predict(features_test).
**
     =» Finally saving The accuracy of deffering the predections and the real test labels using sklearn.metrics.
**
     accuracy_score(labels_test,prediction).
**